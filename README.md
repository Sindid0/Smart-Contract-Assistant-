# ğŸ“œ Smart Contract Assistant

## Overview

A **Retrieval-Augmented Generation (RAG)** web application for analysing legal contracts and documents. Users upload PDF, DOCX, or TXT files through a Gradio interface, which automatically indexes them in a FAISS vector store. The system then answers questions about the uploaded documents with **source citations**, **structured analysis**, and **LLM-as-a-Judge quality evaluation**.

Built with **LangChain Expression Language (LCEL)**, **FAISS** vector search, and **Hugging Face** free-tier models.

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Smart Contract Assistant                         â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Ingestionâ”‚â”€â”€â–¶â”‚  FAISS Index  â”‚â”€â”€â–¶â”‚ Retrieverâ”‚â”€â”€â–¶â”‚  LLM Gen   â”‚ â”‚
â”‚  â”‚ Pipeline â”‚   â”‚ (Embeddings) â”‚   â”‚  (Top-8) â”‚   â”‚ (QA Chain) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â–²                                                  â”‚        â”‚
â”‚       â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â–¼        â”‚
â”‚  PDF/DOCX/TXT        â”‚   Gradio UI  â”‚â—€â”€â”€â”€â”€ Answer + Sources      â”‚
â”‚  (Auto-Ingest)       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

| Component | Technology | Description |
|-----------|-----------|-------------|
| **Embedding Model** | `sentence-transformers/all-MiniLM-L6-v2` | Local, free, 384-dimensional embeddings |
| **LLM** | `meta-llama/Llama-3.1-8B-Instruct` | Cloud (HuggingFace Inference API, free tier) |
| **Vector Store** | FAISS (Facebook AI Similarity Search) | Local, persistent index with incremental merge |
| **Ingestion** | PyPDFLoader, Docx2txtLoader, RecursiveCharacterTextSplitter | Multi-format parsing with 800-char chunks, 200 overlap |
| **RAG Chain** | LangChain LCEL with Long Context Reorder | Dynamic retriever with document re-ranking |
| **Knowledge Base** | Pydantic BaseModel | Running-state tracking (parties, dates, clauses, financials) |
| **Evaluation** | LLM-as-a-Judge | Automated scoring: relevance, groundedness, completeness |
| **Frontend** | Gradio Blocks | Multi-tab UI with auto-ingestion and emerald theme |

## Project Structure

```text
Smart_Contract_Assistant/
â”‚
â”œâ”€â”€ data/                       # Uploaded documents (cleared on each run)
â”œâ”€â”€ vector_store/               # FAISS index (cleared on each run)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Smart_Contract_Assistant_Complete_final_1.ipynb   # Complete notebook
â”œâ”€â”€ .env                        # API Keys (HUGGINGFACEHUB_API_TOKEN)
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## Notebook Sections

The application is contained in a single notebook (`Smart_Contract_Assistant_Complete_final_1.ipynb`) divided into 4 sections:

### Section 1: Configuration & API Setup
- **1.1** â€” Package verification (14 dependencies)
- **1.2** â€” Rich console with emerald-themed output
- **1.3** â€” LLM configuration (`Llama-3.1-8B-Instruct`, `max_new_tokens=1100`, `temp=0.2`, `repetition_penalty=1.4`)
- **1.4** â€” Embedding sanity check with cosine similarity
- **1.5** â€” Simple LCEL chain validation
- **1.6** â€” Utility runnables (`RPrint()`, `docs2str()`)

### Section 2: Document Ingestion Pipeline (ETL)
- **2.1** â€” Fresh start: clears `data/` and `vector_store/` on every run
- **2.2** â€” Document loader (PDF, DOCX, TXT)
- **2.3** â€” Text splitter (800-char chunks, 200 overlap)
- **2.4** â€” Cumulative ingestion with FAISS merge
- **2.5** â€” Batch ingestion with progress tracking and file sizes
- **2.5b** â€” Vector store reset utility
- **2.6** â€” FAISS index inspection and similarity search test

### Section 3: RAG Chain Logic
- **3.1** â€” Imports
- **3.2** â€” FAISS loading with dummy document fallback + top-8 retriever
- **3.3** â€” RAG prompt (demands detailed, structured answers with source citations; bilingual Arabic/English)
- **3.5** â€” Advanced LCEL chain with **dynamic retriever** (`RunnableLambda`) and **grouped context** by source file
- **3.6** â€” `ask_question()` helper with unique source de-duplication
- **3.7** â€” Pydantic `ContractKnowledge` model (parties, dates, clauses, financials, summary)
- **3.8** â€” Conversational `ask_with_history()` with history tracking
- **3.9** â€” RAG evaluation chain (LLM-as-a-Judge with JSON output)

### Section 4: Interactive UI & Assessment
- **4.1** â€” UI imports and session stats initialization
- **4.2** â€” `process_upload()` â€” auto-ingests files, reloads vectorstore, rebuilds retriever + entire chain
- **4.3** â€” `chat_fn()` with `<think>` tag removal and markdown cleanup
- **4.4** â€” UI wrappers (`streaming_chat`, `auto_ingest_wrapper`)
- **4.5** â€” Gradio Blocks UI with 2 tabs:
  - **ğŸ’¬ Chat & Upload** â€” Document upload (multi-file) with auto-ingestion + ChatInterface with example prompts
  - **ğŸ“Š Analysis & Export** â€” Session stats, quality evaluation, knowledge export (JSON)
- **4.6** â€” Server launch with `gr.close_all()`, emerald Soft theme, and custom CSS

## Key Features

- âœ… **Fresh Start** â€” `data/` and `vector_store/` are cleared on each run to avoid stale data
- âœ… **Multi-File Upload** â€” Upload multiple PDF/DOCX/TXT files simultaneously
- âœ… **Auto-Ingestion** â€” Files are automatically indexed when uploaded (no manual step)
- âœ… **Dynamic Retriever** â€” Chain always uses the latest retriever after new uploads
- âœ… **Grouped Context** â€” Retrieved chunks are grouped by source file to prevent the LLM from treating chunks as separate documents
- âœ… **Bilingual Support** â€” Responds in Arabic or English depending on the question
- âœ… **Source Citations** â€” Every answer includes cited source documents and page numbers
- âœ… **LLM-as-a-Judge** â€” Automated evaluation scoring (relevance, groundedness, completeness)
- âœ… **Knowledge Export** â€” Export session data, knowledge base, and conversation history as JSON
- âœ… **Anti-Repetition** â€” `repetition_penalty=1.4` to prevent repeated output

## Quick Start

### 1. Install Dependencies

```bash
# Create virtual environment (Python 3.11 recommended)
python -m venv .venv
.venv\Scripts\activate          # Windows
# source .venv/bin/activate     # Linux/Mac

# Install packages
pip install -r requirements.txt
```

### 2. Configure API Key

Create or edit `.env` in the project root:

```
HUGGINGFACEHUB_API_TOKEN=hf_your_actual_token_here
```

Get a free token at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).

### 3. Run the Notebook

Open in Jupyter or VS Code and run all cells:

```bash
jupyter lab notebooks/Smart_Contract_Assistant_Complete_final_1.ipynb
```

### 4. Upload & Chat

1. The Gradio UI will launch automatically at `http://localhost:7860` (or the next available port).
2. Go to the **ğŸ’¬ Chat & Upload** tab.
3. Upload one or more contract files (PDF/DOCX/TXT).
4. Wait for the **Ingestion Status** to confirm indexing.
5. Ask questions in the chat (e.g., "Summarize all uploaded contracts", "Ù…Ø§ Ù‡ÙŠ Ø´Ø±ÙˆØ· Ø§Ù„Ø¯ÙØ¹ØŸ").
6. View evaluation metrics in the **ğŸ“Š Analysis & Export** tab.

## LLM Configuration

| Parameter | Value | Purpose |
|-----------|-------|---------|
| `max_new_tokens` | 1100 | Longer, more detailed answers |
| `temperature` | 0.2 | Factual, grounded output |
| `top_p` | 0.95 | Controlled sampling |
| `repetition_penalty` | 1.4 | Prevents repeated phrasing |
| `do_sample` | True | Natural language generation |

## Requirements

```
langchain, langchain-community, langchain-huggingface, langchain-text-splitters
faiss-cpu, gradio, pypdf, python-docx, python-dotenv
huggingface_hub, sentence-transformers, ipykernel
docx2txt, rich, pydantic, matplotlib, numpy, scikit-learn
```

## License

This project is for educational and research purposes.
